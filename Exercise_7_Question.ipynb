{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52ab220b-ab7d-4872-97c0-a4a4ca80e966"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top=False,\n",
        "                                weights=None)       # Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False\n",
        "  # Your Code Here\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-11 02:58:56--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  47.8MB/s    in 1.8s    \n",
            "\n",
            "2019-10-11 02:58:58 (47.8 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a9d082d-bc52-4cc7-b73f-33a99fdf7bca"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')  # Your Code Here\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e0f4071-e1af-4ef1-82b5-f9f9b93c3d75"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024,activation='relu')(x)  # Your Code Here\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1,activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "0ea50bcf-84fe-467d-f2ef-8c549fa531b6"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-11 03:02:51--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human   2%[                    ]   4.01M  19.8MB/s               \r/tmp/horse-or-human  22%[===>                ]  32.01M  69.1MB/s               \r/tmp/horse-or-human  44%[=======>            ]  64.01M  92.6MB/s               \r/tmp/horse-or-human  68%[============>       ]  97.31M   109MB/s               \r/tmp/horse-or-human  78%[==============>     ] 112.59M   103MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M   114MB/s    in 1.3s    \n",
            "\n",
            "2019-10-11 03:02:53 (114 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-11 03:02:56--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  19.8MB/s    in 0.6s    \n",
            "\n",
            "2019-10-11 03:02:57 (19.8 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "05b2d17d-ce40-46c7-e397-26eb14a0477c"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses' # Your Code Here\n",
        "train_humans_dir = '/tmp/training/humans'# Your Code Here\n",
        "validation_horses_dir = '/tmp/validation/horses'# Your Code Here\n",
        "validation_humans_dir = '/tmp/validation/humans'# Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir) # Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
        "\n",
        "print('train_horses dataset: '+ str(len(train_horses_fnames)))  # Your Code Here\n",
        "print('train_humans dataset: '+str(len(train_humans_fnames)))\n",
        "print('validation_horses dataset: '+str(len(validation_horses_fnames)))\n",
        "print('validation_humans dataset: '+str(len(validation_humans_fnames)))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_horses dataset: 500\n",
            "train_humans dataset: 527\n",
            "validation_horses dataset: 128\n",
            "validation_humans dataset: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a3482b8-bf81-4120-9f37-d0874c889740"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True) # Your Code Here\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.) # Your Code Here\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150,150)) # Your Code Here     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir, \n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode='binary',\n",
        "                                                         target_size=(150,150)) # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "711c9249-4f72-4239-e06d-4d15504799f2"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback() # Your Code Here\n",
        "history = model.fit_generator(\n",
        "              train_generator,\n",
        "              validation_data = validation_generator,\n",
        "              steps_per_epoch=100,\n",
        "              epochs=20,\n",
        "              validation_steps=50,\n",
        "              verbose=2)    # Your Code Here"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 35s - loss: 0.1939 - acc: 0.9245 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 29s - loss: 0.0780 - acc: 0.9706 - val_loss: 0.0412 - val_acc: 0.9889\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0613 - acc: 0.9799 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0454 - acc: 0.9862 - val_loss: 0.0798 - val_acc: 0.9838\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0514 - acc: 0.9823 - val_loss: 0.0446 - val_acc: 0.9960\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0202 - acc: 0.9914 - val_loss: 0.0338 - val_acc: 0.9960\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0556 - acc: 0.9863 - val_loss: 0.0257 - val_acc: 0.9960\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0353 - val_acc: 0.9960\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0192 - acc: 0.9930 - val_loss: 0.0497 - val_acc: 0.9929\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0286 - acc: 0.9918 - val_loss: 0.1459 - val_acc: 0.9848\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0340 - acc: 0.9909 - val_loss: 0.3551 - val_acc: 0.9575\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0284 - acc: 0.9925 - val_loss: 0.1705 - val_acc: 0.9747\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0281 - acc: 0.9929 - val_loss: 0.1668 - val_acc: 0.9808\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 26s - loss: 0.0164 - acc: 0.9939 - val_loss: 0.1383 - val_acc: 0.9848\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 29s - loss: 0.0229 - acc: 0.9939 - val_loss: 0.0938 - val_acc: 0.9889\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "100/100 - 28s - loss: 0.0190 - acc: 0.9939 - val_loss: 0.2768 - val_acc: 0.9656\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0178 - acc: 0.9940 - val_loss: 0.2636 - val_acc: 0.9727\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0128 - acc: 0.9965 - val_loss: 0.3486 - val_acc: 0.9676\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0222 - acc: 0.9944 - val_loss: 0.1466 - val_acc: 0.9848\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.0240 - acc: 0.9939 - val_loss: 0.4378 - val_acc: 0.9595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1e49893f-2552-4679-a4ed-a79ceb41af0f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n91wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}